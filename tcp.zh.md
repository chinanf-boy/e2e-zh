
# {{Paj.Toe}}

与像UDP这样的简单解复用协议相比,更复杂的传输协议是提供可靠的ㄡ面向连接的字节流服务的协议. 事实证明,这种服务对于各种各样的应用程序都很有用,因为它使应用程序不必担心丢失或重新排序的数据. Internet的传输控制协议可能是这种类型的使用最广泛的协议,也是经过最仔细调优的协议. 正是由于这两个原因,本节详细地研究了TCP,尽管我们在本节末尾识别并讨论可选的设计选择. 

根据本章开头问题说明中给出的传输协议的特性,TCP保证了字节流的可靠有序传递. 它是一个全双工协议,这意味着每个TCP连接支持一对字节流,每个字节流在每个方向上流动. 它还包括用于这些字节流中的每一个的流控制机制,该机制允许接收器限制发送器在给定时间可以发送多少数据. 最后,与UDP一样,TCP支持解复用机制,该机制允许任何给定主机上的多个应用程序同时与其对等方进行对话. 除了上述特性之外,TCP还实现了高度调谐 (并且仍在发展) 的拥塞控制机制. 这种机制的思想是控制TCP发送数据的速度,不是为了防止发送方超载接收机,而是为了防止发送方超载网络. TCP的拥塞控制机制的描述被推迟到下一章,在下一章中,我们将在如何公平地分配网络资源的更大上下文中讨论它. 

由于许多人混淆了拥塞控制和流量控制,所以我们重申了差异. *流量控制*涉及防止发送者过度接管接收者的能力. *拥塞控制*涉及防止过多的数据被注入网络,从而导致交换机或链路过载. 因此,流量控制是一个端到端的问题,而拥塞控制涉及主机和网络如何相互作用. 

## 端到端问题

TCP的核心是滑动窗口算法. 尽管这与链路级经常使用的基本算法相同,但是因为TCP在因特网上而不是在物理点对点链路上运行,所以存在许多重要的差异. 这一部分标识了这些差异并解释了它们如何复杂化TCP. 接下来的小节描述了TCP如何解决这些和其他并发症. 

首先,尽管所提出的链路级滑动窗口算法运行在总是连接相同两台计算机的单个物理链路上,但是TCP支持在因特网上任何两台计算机上运行的进程之间的逻辑连接. 这意味着TCP需要一个明确的连接建立阶段,在该阶段中,连接的双方同意彼此交换数据. 这种差异类似于必须拨号对方,而不是有一个专用的电话线. TCP还具有明确的连接拆解阶段. 在连接建立期间所发生的事情之一是双方建立某种共享状态以使滑动窗口算法能够开始. 连接拆卸是需要的,因此每个主机都知道释放这个状态是可以的. 

第二,尽管总是连接相同两台计算机的单个物理链路具有固定的往返时间 (RTT) ,但是TCP连接可能具有非常不同的往返时间. 例如,在旧金山的主机和波士顿的主机之间相隔几千公里的TCP连接可能具有100毫秒的RTT,而在同一房间内的两个主机之间相隔几米的TCP连接可能具有仅1毫秒的RTT. toCoL必须能够支持这两种连接. 更糟糕的是,旧金山和波士顿的主机之间的TCP连接可能在凌晨3点具有100毫秒的RTT,但在下午3点具有500毫秒的RTT. 在仅持续几分钟的单个TCP连接期间,RTT的变化甚至可以实现. 这对滑动窗口算法意味着,触发重传的超时机制必须是自适应的.  (当然,点对点链路的超时必须是可设置的参数,但是没有必要为特定的节点对调整这个定时器. ) 

第三个区别是,分组可以在它们穿过因特网时重新排序,但是这在点对点链路上是不可能的,其中放入链路一端的第一分组必须首先出现在另一端. 由于滑动窗口算法能够使用序列号正确地重新排序分组,所以稍微失序的分组不会造成问题. 真正的问题是数据包的无序程度有多大. `TTL`) 字段过期,此时包被丢弃 (因此不会有迟到的危险) . 知道IP在他们之后丢掉数据包`TTL`到期时,TCP假定每个数据包具有最大的生存期. 确切的寿命,称为*最大节段寿命* (MSL) 是一种工程选择. 当前推荐设置为120秒. 请记住,IP并不直接执行这个120秒的值;TCP只是保守地估计一个分组在因特网上可能存在多长时间. 其含义是显著的-TCP必须准备用于非常旧的分组突然出现在接收器,可能混淆滑动窗口算法. 

第四,连接到点到点链路的计算机通常被设计为支持链路. 例如,如果一个链路的延迟$乘以$$带宽乘积被计算为8KB,这意味着一个窗口大小被选择为允许在给定时间最多8KB数据没有被确认,那么链路两端的计算机可能具有缓冲多达8KB的d的能力. 阿塔. 否则,设计系统是愚蠢的. 另一方面,几乎任何类型的计算机都可以连接到因特网,使得专用于任何一个TCP连接的资源量高度可变,特别是考虑到任何一个主机可能同时支持数百个TCP连接. 这意味着TCP必须包括一个机制,每方都使用这个机制来"学习"对方能够应用到连接的资源 (例如,多少缓冲空间) . 这就是流量控制问题. 

第五,因为直接连接的链路的发送侧不能比链路的带宽允许的更快地发送,并且只有一个主机正在向链路中泵送数据,所以不可能在不知不觉中使链路拥塞. 换句话说,链路上的负载以发送方的分组队列的形式可见. 相比之下,TCP连接的发送端不知道将遍历哪些链路以到达目的地. 例如,发送机可以直接连接到相对快速的以太网,并且能够以100Mbps的速率发送数据,但是在网络中央的某个地方,必须遍历1.5Mbps T1链路. 更糟糕的是,由不同来源产生的数据可能会试图穿越同一个慢链路. 这导致了网络拥塞的问题. 这个话题的讨论被推迟到下一章. 

我们通过将TCP提供可靠/有序传递服务的方法与X.25网络使用的方法进行比较,来结束对端到端问题的讨论. 在TCP中,假定底层IP网络不可靠并且无序地传递消息;TCP在端到端的基础上使用滑动窗口算法来提供可靠/有序的传递. 相比之下,X.25网络在逐网的基础上使用网络内的滑动窗口协议. 这种方法背后的假设是,如果消息被可靠地传递并且沿着源主机和目的地主机之间的路径在每对节点之间按顺序传递,那么端到端服务还保证可靠/有序的传递. 

后一种方法的问题在于,逐跳保证序列不一定与端到端保证相加. 首先,如果向路径的一端添加异构链路 (例如,以太网) ,则无法保证此跳将保留与其他跳相同的服务. 第二,仅仅因为滑动窗口协议保证消息从节点A正确地传递到节点B,然后从节点B正确地传递到节点C,它不能保证节点B的行为完美. 例如,已知网络节点在将错误从输入缓冲区传输到输出缓冲区的同时将错误引入消息. 他们也知道意外地重新排序消息. 由于这些弱点的小窗口,仍然需要提供真正的端到端检查以保证可靠/有序的服务,即使系统的较低级别也实现该功能. 

这个讨论用来说明系统设计中最重要的原则之一. *端对端观点*. 简而言之,端到端参数表示,除非可以在系统的较低级别完全且正确地实现函数 (在我们的示例中,提供可靠的/有序的交付) ,否则不应该在系统的较低级别中提供函数. 因此,该规则支持TCP/IP方法. 然而,这个规则不是绝对的. 它允许函数作为性能优化不完全提供在低水平. 这就是为什么在逐跳的基础上执行错误检测 (例如,CRC) 与端到端参数完全一致的原因;跨一跳检测和重传单个损坏包比必须端到端重传整个文件更可取. 

## 段格式

TCP是面向字节的协议,这意味着发送方将字节写入TCP连接,而接收方从TCP连接中读取字节. 虽然"字节流"描述了Servi[图1](#tcp-stream),为了简单起见,显示数据只在一个方向上流动. 请记住,一般来说,单个TCP连接支持在两个方向上流动的字节流. 

<figure class="line">
	<a id="tcp-stream"></a>
	<img src="figures/f05-03-9780123850591.png" width="500px"/>
	<figcaption>How TCP manages a byte stream.</figcaption>
</figure>

TCP对等体间交换的数据包[图1](#tcp-stream)被称为*部分*,因为每一个都携带字节流的一部分. 每个TCP段包含示意性地描绘的头部. [图2](#tcp-format). 在这一节中,大多数这些领域的相关性将变得明显. 现在,我们简单介绍一下. 

<figure class="line">
	<a id="tcp-format"></a>
	<img src="figures/f05-04-9780123850591.png" width="400px"/>
	<figcaption>TCP header format.</figcaption>
</figure>

这个`SrcPort`和`DstPort`字段分别标识源端口和目的端口,就像UDP一样. 这两个字段,加上源和目的IP地址,组合起来唯一地标识每个TCP连接. 也就是说,TCP的DEMUX密钥是由4元组给出的. 

```pseudo
(SrcPort, SrcIPAddr, DstPort, DstIPAddr)
```

注意,因为TCP连接来来往往,所以可能建立特定端口对之间的连接,用于发送和接收数据,然后关闭,然后在稍后的时间同一对端口参与第二连接. 我们有时把这种情况称为两种不同的情况. *化身*相同的连接. 

这个`Acknowledgement`,`SequenceNum`和`AdvertisedWindow`在TCP的滑动窗口算法中都涉及字段. 因为TCP是面向字节的协议,所以每个字节的数据都有序列号. 这个`SequenceNum`字段包含在该段中携带的数据的第一字节的序列号,以及`Acknowledgement`和`AdvertisedWindow`字段携带关于流向另一方向的数据流的信息. 为了简化我们的讨论,我们忽略了这样一个事实,即数据可以双向流动,并且我们专注于具有特定内容的数据`SequenceNum`单向流动`Acknowledgement`和`AdvertisedWindow`在相反方向上流动的值,如图所示[图3](#tcp-flow). 这三个领域的使用将在本章后面更全面地描述. 

<figure class="line">
	<a id="tcp-flow"></a>
	<img src="figures/f05-05-9780123850591.png" width="500px"/>
	<figcaption>Simplified illustration (showing only one direction)
	of the TCP process, with data flow in one direction and ACKs in
	the other.</figcaption>
</figure>

6位`Flags`字段用于中继TCP节点之间的控制信息. 可能的标志包括`SYN`,`FIN`,`RESET`,`PUSH`,`URG`和`ACK`. 这个`SYN`和`FIN`当分别建立和终止TCP连接时使用标志. 它们的用途将在后面的章节中描述. 这个`ACK`任何时候都设置标志`Acknowledgement`字段是有效的,这意味着接收者应该注意它. 这个`URG`标志表示此段包含紧急数据. 设置此标志时,`UrgPtr`字段指示该段中包含的非紧急数据的起始位置. 紧急数据包含在段体的前面,包括并包括一个值. `UrgPtr`字节到段中. 这个`PUSH`标志表示发送方调用了push操作,它向TCP的接收方指示它应该将此事实通知接收过程. 在后面的部分中我们将讨论这些最后两个特征. 最后,`RESET`标志表示接收器已经变得混淆-例如,因为它接收到一个它不希望接收的段-因此想要中止连接. 

最后,`Checksum`字段的使用方式与UDP完全相同,它是通过TCP报头ㄡTCP数据和伪报头计算的,伪报头由来自IP报头的源地址ㄡ目的地址和长度字段组成. 在IPv4和IPv6中,TCP都需要校验和. 此外,由于TCP报头的长度可变 (可以在强制字段之后附加选项) ,所以`HdrLen`字段包含在32位字中给出标头的长度. 这个领域也被称为`Offset`字段,因为它测量从数据包开始到数据开始的偏移量. 

## 连接建立与终止

TCP连接开始于客户端 (呼叫者) 对服务器 (被调用方) 进行主动打开. 假设服务器先前进行了被动打开,则双方进行消息交换以建立连接. (回想第1章,希望发起连接的一方执行主动打开,而愿意接受连接的一方执行被动打开. )只有在该连接建立阶段结束后,双方才开始发送数据. 同样,一旦参与者发送完数据,它就关闭连接的一个方向,这导致TCP发起一轮连接终止消息. 注意,虽然连接设置是不对称的活动 (一侧是被动打开的,另一侧是主动打开的) ,但是连接拆卸是对称的 (每侧必须独立地关闭连接) . 因此,一方可能已经关闭了,这意味着它不能再发送数据,但是另一方保持双向连接的另一半打开并继续发送数据. 

> 更确切地说,连接设置可以是对称的,双方试图同时打开连接,但通常的情况是一方进行主动打开,而另一方进行被动打开. 

### 三向交握

TCP用来建立和终止连接的算法称为*三次握手*. 我们首先描述基本算法,然后展示它是如何被TCP使用的. 三向握手涉及在客户端和服务器之间交换三个消息,如[图4](#twh-timeline).

<figure class="line">
	<a id="twh-timeline"></a>
	<img src="figures/f05-06-9780123850591.png" width="400px"/>
	<figcaption>Timeline for three-way handshake algorithm.</figcaption>
</figure>

其思想是双方希望就一组参数达成一致,在开启TCP连接的情况下,这些参数是双方计划用于各自字节流的起始序列号. 一般来说,参数可能是任何一方都希望对方知道的事实. 首先,客户端 (活动参与者) 向服务器 (被动参与者) 发送一个段,说明它计划使用的初始序列号 (`Flags`=`SYN`,`SequenceNum`= x) . 然后服务器用一个既能确认客户端序列号又能响应的单一段来响应 (`Flags =
ACK, Ack = x + 1`并声明其自己的起始序列号 (`Flags = SYN, SequenceNum = y`) 也就是说,两者都`SYN`和`ACK`位设置在`Flags`第二条消息的字段. 最后,客户端用一个第三段来响应服务器的序列号. `Flags = ACK, Ack = y + 1`) 每一方确认序列号大于发送一个的序列号的原因是`Acknowledgement`字段实际上标识了"预期的下一个序列号",从而隐式地承认所有先前的序列号. 虽然在此时间线中未示出,但是为前两个片段中的每一个调度定时器,并且如果未接收到预期的响应,则重新传输片段. 

您可能会问自己,为什么客户端和服务器在连接建立时必须彼此交换启动序列号. 如果每一方简单地以一些"众所周知"的序列号开始,例如0,则会更简单. 事实上,TCP规范要求连接的每一侧随机选择初始起始序列号. 这样做的原因是为了防止同一连接的两个化身过早地重复使用相同的序列号,也就是说,尽管来自连接的较早化身的段仍有可能干扰连接的较晚化身. 

### 状态转移图

TCP是足够复杂的,它的规范包括状态转换图. 此图的副本给出. [图5](#tcp-std). 这个图表只显示了打开连接 (高于ESTABLISHED的一切) 和关闭连接 (低于ESTABLISHED的一切) 所涉及的状态. 连接打开时进行的所有操作 (即滑动窗口算法的操作) 都隐藏在ESTABLISHED状态. 

<figure class="line">
	<a id="tcp-std"></a>
	<img src="figures/f05-07-9780123850591.png" width="600px"/>
	<figcaption>TCP state-transition diagram.</figcaption>
</figure>

TCP的状态转换图是相当容易理解的. 每个循环表示TCP连接的一端可以发现自身的状态. 所有连接都在关闭状态下开始. 随着连接的进行,连接根据状态从状态移动到状态. 每个弧都用表格的标记来标记. *事件/行动*. 因此,如果连接处于侦听状态,SYN段到达 (即,与`SYN`标记集) ,连接向SythRCVD状态过渡,并采取与`ACK+SYN`段. 

注意,有两种事件触发状态转换:  (1) 段从对等点到达 (例如,从LISTEN到SYN的弧上的事件) γRCVD) ,或 (2) 本地应用进程调用TCP上的操作 (例如,*主动开放*从闭合到SYN的弧上的事件γ发送) . 换言之,TCP的状态转移图有效地定义了*语义*它的对等接口和它的服务接口. 这个*句法*这两个接口由分段格式给出 (如图所示) . [图2](#tcp-format)) 和一些应用程序编程接口,如Socket API. 

现在让我们来追踪图中的典型转变. [图5](#tcp-std). 请记住,在连接的每一端,TCP都会从状态到状态进行不同的转换. 当打开连接时,服务器首先调用TCP上的被动打开操作,这会导致TCP移动到LISTEN状态. 稍后,客户端进行活动打开,这将导致其连接端向服务器发送SYN段并移动到SYNγ发送状态. 当SYN段到达服务器时,它移动到SYN. γRCVD状态,并用SYN+ACK段进行响应. 此段的到达导致客户端移动到已建立的状态,并向服务器发送ACK. 当此ACK到达时,服务器最终移动到已建立状态. 换言之,我们刚刚追踪了三次握手. 

关于连接建立一半的状态转换图,需要注意三件事. 首先,如果客户端对服务器的ACK丢失,对应于三方握手的第三步,那么连接仍然正常工作. 这是因为客户端已经处于ESTABLISHED状态,所以本地应用程序进程可以开始向另一端发送数据. 这些数据段中的每一个都将具有`ACK`标志集和正确的值在`Acknowledgement`字段,因此当第一个数据段到达时,服务器将移动到已建立的状态. 这实际上是TCP的一个重要方面ℴℴ每个段报告发送方接下来希望看到的序列号,即使该序列号重复包含在一个或多个先前段中的相同序列号. 

关于状态转换图,需要注意的第二件事情是,每当本地进程调用*发送*TCP操作. 也就是说,被动参与者可以识别连接的两端 (即,它自己和它愿意连接到它的远程参与者) ,然后让它改变对等待对方的想法,而是主动建立连接. 据我们所知,这是TCP的一个特点,没有应用程序实际上利用. 

最后要注意的是图中没有显示的弧. 具体而言,涉及向对方发送段的大多数状态还计划一个超时,如果预期响应没有发生,该超时最终导致段出现. 这些重传在状态转移图中没有描述. 如果几次尝试之后预期的响应没有到达,TCP放弃并返回到关闭状态. 

现在我们将注意力转向终止连接的过程,需要牢记的重要一点是,连接两侧的应用程序进程必须独立地关闭其连接的一半. 如果只有一侧关闭连接,则这意味着它没有更多的数据要发送,但是仍然可以从另一侧接收数据. 这使得状态转移图复杂化,因为它必须考虑到双方调用*关闭*同时,还有一方调用close的可能性,随后,另一方调用close的可能性. 因此,在任何一边,都有三种转换组合,它们将连接从ESTABLISHED状态转换为CLOSED状态: 

-   这一方首先关闭: 已建立的$$$$$$$$FINγ等待γ1美元\\右行$$FINγWaITY2 $ $\\右行$$时间γ等待$$\\TraveReal$$关闭. 

-   另一方首先关闭: 建立$$$Real$$$收盘γ等待$$右行$$最后γACK $ $\\右行$$关闭. 

-   双方同时关闭: 建立了$$$$$$$FINγ等待γ1美元$\\右行$$收盘$$\\右行$$时间γ等待$$\\TraveReal$$关闭. 

实际上,有第四个,虽然稀有,一系列的跃迁,导致了闭合状态;它遵循来自鳍的弧. γ等待γ1到时间γ等待. 我们把它作为一个练习,让你弄清楚是什么环境导致了第四种可能性. 

关于连接拆卸的主要认识是时间上的连接. γ等待状态不能移动到关闭状态,直到它已经等待IP数据报在因特网上可能存在的最大时间量(即,120秒)的两倍. 其原因是,尽管连接的本地端已经响应于对方的FIN段发送了ACK,但它不知道ACK已经成功传递. 因此,另一侧可能重传其鳍片段,并且该第二鳍片段可能在网络中被延迟. 如果允许连接直接移动到CLOSED状态,那么可能出现另一对应用程序进程并打开同一连接 (即,使用同一对端口号) ,并且从连接的早期化身开始的延迟FIN段将立即初始化结束了这一连接的后来化身. 

## 滑动窗口再访问

现在我们准备讨论TCP对滑动窗口算法的变体,它有几个目的: (1)它保证数据的可靠传送,(2)它保证数据按顺序传送,(3)它强制在发送者和接收者之间进行流控制. TCP对滑动窗口算法的使用与在这三个函数的前两个情况下的链路级相同. TCP与较早的算法不同之处在于它也折叠了流控制功能. 特别地,不是具有固定大小的滑动窗口,而是接收器. *做广告*给发送者的窗口大小. 这是用`AdvertisedWindow`TCP报头中的字段. 然后,发送者被限制为不超过一个值. `AdvertisedWindow`在任何给定时间的未确认数据的字节. 接收器选择合适的值. `AdvertisedWindow`基于为缓冲数据而分配给连接的内存量. 这个想法是让发送者不要超过接收者的缓冲区. 我们在下面讨论更大的长度. 

### 可靠有序交货

要了解TCP的发送和接收端如何相互交互以实现可靠和有序的传递,请考虑[图6](#tcp-fc). 发送端的TCP维护发送缓冲区. 该缓冲区用于存储已经发送但尚未确认的数据,以及已经由发送应用程序写入但未发送的数据. 在接收端,TCP保持接收缓冲器. 该缓冲区保存顺序不正确的数据以及顺序正确的数据 (即,流中没有丢失的字节) ,但是应用程序进程还没有机会读取. 

<figure class="line">
	<a id="tcp-fc"></a>
	<img src="figures/f05-08-9780123850591.png" width="500px"/>
	<figcaption>Relationship between TCP send buffer (a) and receive
	buffer (b).</figcaption>
</figure>

为了使下面的讨论更容易理解,我们首先忽略缓冲区和序列号都是有限大小的,因此最终将绕过这个事实. 此外,我们不区分到缓冲区中的指针 (其中存储了特定字节的数据) 和该字节的序列号. 

首先查看发送端,将三个指针保存到发送缓冲区中,每个指针具有明显的含义: `LastByteAcked`,`LastByteSent`和`LastByteWritten`. 显然,

```pseudo
LastByteAcked <= LastByteSent
```

因为接收器不能确认尚未发送的字节,并且

```pseudo
LastByteSent <= LastByteWritten
```

因为TCP无法发送应用程序进程尚未写入的字节. 还要注意,左边的字节中没有一个`LastByteAcked`需要保存在缓冲区中,因为它们已经被确认,并且没有右边的字节. `LastByteWritten`需要缓冲,因为它们还没有生成. 

在接收端保持一组类似的指针 (序列号) : `LastByteRead`,`NextByteExpected`和`LastByteRcvd`. 然而,由于无序交货问题,这些不等式有点不那么直观. 第一关系

```pseudo
LastByteRead < NextByteExpected
```

是正确的,因为在接收到一个字节之前,它不能被应用程序读取. *和*所有前面的字节也被接收. `NextByteExpected`指向最新字节之后的字节,以满足此标准. 第二,

```pseudo
NextByteExpected <= LastByteRcvd + 1
```

既然数据已经有序到达,`NextByteExpected`指向字节后`LastByteRcvd`而如果数据已经出故障,那么`NextByteExpected`指向数据中第一个间隙的开始,如[图6](#tcp-fc). 注意左边的字节`LastByteRead`不需要缓冲,因为它们已经被本地应用程序进程读取,右边的字节已经被读取. `LastByteRcvd`不需要缓冲,因为他们还没有到达. 

### 流量控制

上面的大部分讨论与标准滑动窗口算法中的讨论类似;唯一的真正区别在于,这次我们详细说明了发送和接收应用程序进程分别填充和清空它们的本地缓冲区的事实.  (前面的讨论掩盖了从上游节点到达的数据正在填充发送缓冲区和被发送到下游节点的数据正在清空接收缓冲区的事实. ) 

在继续之前,您应该确保已经理解了这一点,因为现在到了两个算法差异更大的时候. 在下面,我们再次介绍两个缓冲器都是有限大小的事实. `MaxSendBuffer`和`MaxRcvBuffer`,虽然我们不担心他们如何实施的细节. 换句话说,我们只关心缓冲的字节数,而不是实际存储的字节数. 

回想一下,在滑动窗口协议中,窗口的大小设置可以在不等待接收方确认的情况下发送的数据量. 因此,接收器通过对不大于其可缓冲的数据量的窗口进行广告来节制发送器. 注意接收端的TCP必须保持

```pseudo
LastByteRcvd - LastByteRead <= MaxRcvBuffer
```

避免溢出它的缓冲液. 因此,它的窗口大小为

```pseudo
AdvertisedWindow = MaxRcvBuffer - ((NextByteExpected - 1) - LastByteRead)
```

它表示在其缓冲区中剩余的自由空间量. 当数据到达时,接收者确认它,只要所有前面的字节也到达. 此外,`LastByteRcvd`向右移动 (递增) ,这意味着广告窗口可能缩小. 它是否收缩取决于本地应用程序消耗数据的速度. 如果本地进程正在快速读取数据 (导致) `LastByteRead`以相同的速率递增`LastByteRcvd`然后,广告窗口保持打开 (即,`AdvertisedWindow = MaxRcvBuffer`) 然而,如果接收过程落后,可能是因为它对读取的每个字节的数据执行非常昂贵的操作,那么广告窗口随着每个到达的段而变小,直到最终变为0. 

发送端的TCP必须遵循从接收方获取的广告窗口. 这意味着,在任何给定的时间,它必须确保

```pseudo
LastByteSent - LastByteAcked <= AdvertisedWindow
```

换句话说,发送者计算一个*有效的*限制它可以发送多少数据的窗口: 

```pseudo
EffectiveWindow = AdvertisedWindow - (LastByteSent - LastByteAcked)
```

显然,`EffectiveWindow`在源可以发送更多数据之前,必须大于0. 因此,一段可能到达X字节,从而允许发送者增加. `LastByteAcked`通过x,但是因为接收过程没有读取任何数据,所以广告窗口现在比以前小x字节. 在这种情况下,发送者将能够释放缓冲区空间,但不发送任何更多的数据. 

在进行此操作的同时,发送端还必须确保本地应用程序进程不会溢出发送缓冲区,即,

```pseudo
LastByteWritten - LastByteAcked <= MaxSendBuffer
```

如果发送过程试图将Y字节写入TCP,但

```pseudo
(LastByteWritten - LastByteAcked) + y > MaxSendBuffer
```

然后TCP阻止发送过程,并且不允许它产生更多的数据. 

现在可以理解慢接收过程如何最终停止快速发送过程. 首先,接收缓冲区填满,这意味着广告窗口缩小到0. 通告的窗口0表示发送方不能发送任何数据,即使它先前发送的数据已经被成功确认. 最后,不能传输任何数据意味着发送缓冲区已满,这最终导致TCP阻塞发送进程. 一旦接收进程再次开始读取数据,接收侧TCP就能够打开其窗口备份,这允许发送侧TCP从其缓冲区发送数据. 当这些数据最终被确认时,`LastByteAcked`递增,保存该确认数据的缓冲区空间变为空闲,并且解除阻塞并允许发送过程继续. 

剩下的一个细节必须解决ℴℴ发送方如何知道广告窗口不再为0?如上所述,TCP*总是*响应接收到的数据段发送一个段,该响应包含最新的值`Acknowledge`和`AdvertisedWindow`字段,即使这些值自上次发送以来也没有改变. 问题是这样的. 一旦接收方已经通告了窗口大小为0,发送方就不允许发送更多的数据,这意味着它无法发现所通告的窗口在未来某个时间不再是0. TCP在接收端不自发地发送非数据段;它只响应于到达的数据段发送它们. 

TCP处理这种情况如下. 每当对方广告窗口大小为0时,发送方坚持每隔一段时间发送一个具有1字节数据的段. 它知道这个数据可能不会被接受,但是它尝试了,因为每个1字节段都会触发包含当前广告窗口的响应. 最终,这些1字节探针中的一个触发响应,报告一个非零广告窗口. 

请注意,发送端周期性地发送这个探测段的原因是TCP被设计成使接收端尽可能简单ℴℴ它简单地响应来自发送方的段,并且它从不自己发起任何活动. 这是一个众所周知 (尽管不是普遍适用的) 协议设计规则的示例,由于缺少更好的名称,我们将其称为*智能发送器/哑铃接收机*规则. 回想一下,当我们讨论了NKS在滑动窗口算法中的使用时,我们看到了另一个例子. 

### 防缠绕

这个小节和下一节考虑了`SequenceNum`和`AdvertisedWindow`字段及其大小对TCP的正确性和性能的影响. TCP`SequenceNum`字段长32位,其`AdvertisedWindow`字段长16位,这意味着TCP很容易满足滑动窗口算法的要求,即序列号空间是窗口大小的两倍: 2$^{32}$$>>2$$\\乘以$$2$^{16}$$$$. 然而,这一要求并不是这两个领域的有趣之处. 依次考虑每个字段. 

32位序列号空间的相关性是,在给定连接上使用的序列号可以围绕-具有序列号S的字节可以一次发送,然后在稍后时间可以发送具有相同序列号S的第二字节. 再次,我们假设数据包不能生存在互联网上比推荐的MSL更长. 因此,我们目前需要确保序列号不在120秒的时间内环绕. 这是否发生取决于在因特网上传输数据的速度,即32位序列号空间的消耗速度.  (本讨论假设我们试图尽可能快地消耗序列号空间,但是如果我们正在完成保持管道满负荷的工作,当然会消耗序列号空间. ) [表1](#eqnum)显示序列号在具有不同带宽的网络上需要多长时间. 

<a id="seqnum"></a>

|         带宽        | 直到包裹的时间 |
| :---------------: | :-----: |
|   T1 (1.5 Mbps)   |  6.4小时  |
|   以太网 (10 Mbps)   |   57分钟  |
|   T3 (45 Mbps)    |   13分钟  |
| 快速以太网 (100~Mbps)  |   6分钟   |
|  OC-3 (155 Mbps)  |   4分钟   |
| OC-12 (622 Mbps)  |   55秒   |
| OC-48 (2.5 Gbps)  |   14秒   |

{%中心%}*表1. 直到32位序列号空间围绕. *{%EndoCtC%}

如您所见,32位序列号空间对于当今网络上遇到的大多数情况都是足够的,但是考虑到OC-192链接存在于Internet主干网中,并且大多数服务器现在都具有千兆位以太网 (或10Gbps) 接口,它已经接近32位的位置. 太小了. 幸运的是,IETF已经完成了对TCP的扩展,有效地扩展了序列号空间,从而防止了序列号被包围. 这个和相关的扩展在后面的部分中描述. 

### 管满

16位的相关性`AdvertisedWindow`字段是必须足够大以允许发送方保持管道满. 显然,接收器可以自由地打开不至于像`AdvertisedWindow`字段允许;我们感兴趣的是接收机有足够的缓冲空间来处理尽可能多的数据`AdvertisedWindow`允许. 

在这种情况下,它不仅仅是网络带宽,而是延迟$$ \\ $$带宽产品,决定了它有多大. `AdvertisedWindow`字段需要-窗口需要打开得足够远,以允许传输价值为$乘以$带宽产品的完整延迟. 假设一个100米的RTT (在美国的跨国连接的典型数字) ,[表2](#adv-win)为几个网络技术提供延迟$$ \\ $$带宽产品. 

<a id="adv-win"></a>

|         带宽        | 延迟$$$乘以$$产品 |
| :---------------: | :---------: |
|   T1 (1.5 Mbps)   |    18千字节    |
|   以太网 (10 Mbps)   |    122千字节   |
|   T3 (45 Mbps)    |    549千字节   |
| 快速以太网 (100 Mbps)  |    1.2兆字节   |
|  OC-3 (155 Mbps)  |    1.8兆字节   |
| OC-12 (622 Mbps)  |    7.4兆字节   |
| OC-48 (2.5 Gbps)  |   29.6兆字节   |

{%中心%}*表2. 所需窗口大小为100毫秒RTT. *{%EndoCtC%}

正如你所看到的,TCP`AdvertisedWindow`场的形状比它的更糟`SequenceNum`字段-它不够大,甚至不能处理横跨美国大陆的T3连接,因为16位字段允许我们广告窗口只有64KB. 上面提到的TCP扩展提供了一种有效增加广告窗口大小的机制. 

## 触发传输

接下来我们考虑一个出乎意料的微妙问题: TCP是如何决定传输一个段的. 如前所述,TCP支持字节流抽象;即,应用程序将字节写入流,并且由TCP决定是否有足够的字节来发送段. 决定这个决定的因素是什么?

如果我们忽略了流控制的可能性,也就是说,我们假设窗口是敞开的,就像连接第一次启动时一样,那么TCP有三种机制来触发段的传输. 首先,TCP维护一个变量,通常称为*最大段尺寸* (`MSS`) ,它一收集就发送一段. `MSS`发送过程中的字节. `MSS`通常设置为TCP可以发送的最大段的大小,而不会导致本地IP碎片. 也就是说,`MSS`设置为直接连接网络的最大传输单元 (MTU) ,减去TCP和IP报头的大小. 触发TCP传输段的第二件事是发送过程已经明确地要求它这样做. 具体来说,TCP支持*推*操作,发送过程调用此操作以有效地刷新未发送字节的缓冲区. 传输段的最后一个触发器是定时器触发;所得到的段包含当前缓冲用于传输的字节数. 然而,正如我们将很快看到的,这个"计时器"并不是你所期望的. 

### 糊涂窗口综合症

当然,我们不能忽视流控制,它在抑制发送器中起着明显的作用. 如果发送者`MSS`要发送的字节数和窗口至少打开得那么多,然后发送方发送完整的段. 但是,假设发送器正在累积要发送的字节,但当前窗口已关闭. 现在假设一个ACK到达,有效地打开窗口足够的发送者发送,例如,`MSS/2`字节. 发送方是否发送一个半满段或等待窗口打开到一个满`MSS`?最初的规范对此保持沉默,TCP的早期实现决定继续进行并发送半个完整的段. 毕竟,在窗户打开之前,还不知道会持续多久. 

事实证明,积极利用任何可用窗口的策略导致现在被称为*糊涂窗口综合症*.[图7](#sillywindow)帮助可视化发生的事情. 如果您将TCP流看作一个传送带,其中"满"容器 (数据段) 朝一个方向传送,而空容器 (ACK) 朝相反方向传送,那么`MSS`大小的段对应于大容器,1字节段对应于非常小的容器. 只要发送方正在发送`MSS`-大小段和接收器ACK至少一个`MSS`数据一次,一切都好 ([图7 (a) ](#sillywindow)) 但是,如果接收者不得不缩小窗口,那么发送者有时不能发送完整的内容. `MSS`数据?如果发送者积极地填充小于`MSS`一旦容器到达,接收方将确认较小的字节数,因此引入系统的小容器将无限期地留在系统中. 也就是说,它立即在每一端被填充和清空,并且从不与相邻的容器合并以创建更大的容器,如[图7 (b) ](#sillywindow). 当TCP的早期实现经常发现自己以微小的片段填充网络时,就发现了这种情况. 

<figure class="line">
	<a id="sillywindow"></a>
	<img src="figures/f05-09-9780123850591.png" width="500px"/>
	<figcaption>Silly window syndrome. (a) As long as the sender sends
	MSS-sized segments and the receiver ACKs one MSS at a time, the
	system works smoothly. (b) As soon as the sender sends less than
	one MSS, or the receiver ACKs less than one MSS, a small
	"container" enters the system and continues to circulate.</figcaption>
</figure>

请注意,愚蠢的窗口综合症只是当发送方发送一小段或者接收方打开一小段窗口时出现的问题. 如果这两种情况都不发生,那么小容器就不会被引入到流中. 禁止发送小片段是不可能的,例如,应用程序可能会执行*推*发送一个字节之后. 然而,有可能保持接收器不引入一个小容器 (即,一个小的打开的窗口) . 规则是,在广告一个零窗口之后,接收机必须等待等于一个`MSS`在它宣传一个打开的窗口之前. 

由于我们无法消除将一个小容器引入流的可能性,因此我们还需要机制来合并它们. 接收机可以通过延迟ACK来实现这一点,发送一个组合的ACK而不是多个较小的ACK,但这只是部分解决方案,因为接收机无法知道延迟多长时间可以安全地等待另一段到达或应用程序读取更多数据.  (这样打开窗户) . 最终的解决方案落在发送者身上,这让我们回到我们最初的问题: TCP发送者何时决定传输一个段?

### Nagle算法

返回到TCP发送器,如果有数据要发送,但窗口小于`MSS`然后,我们可能需要等待一些时间才能发送可用的数据,但问题是多长时间?如果我们等待太久,就会伤害到像Telnet这样的交互式应用程序. 如果我们不等待足够长的时间,那么我们就冒着冒着一大堆小包掉进愚蠢窗口综合症的危险. 答案是引入定时器,并在定时器到期时进行传输. 

虽然我们可以使用一个基于时钟的定时器,例如每100毫秒的Nagle就推出了一个优雅的计时器. *自计时*解决方案. 这个想法是,只要TCP在飞行中有任何数据,发送者最终会收到一个ACK. 这个ACK可以像一个定时器发射,触发更多数据的传输. Nagle算法提供了一个简单ㄡ统一的规则来决定何时发送: 

```pseudo
When the application produces data to send
    if both the available data and the window >= MSS
        send a full segment
    else
        if there is unACKed data in flight
            buffer the new data until an ACK arrives
        else
            send all the new data now
```

换句话说,如果窗口允许的话,发送一个完整的段总是可以的. 如果当前传输中没有段,则立即发送少量数据也是可以的,但是如果传输中有任何段,则发送方必须在发送下一个段之前等待ACK. 因此,如Telnet,持续写入一个字节的时间交互应用的速度在每一段时间发送数据. 段将包含一个单字节,而其他的人将包含多字节的用户能够在一个往返时间类型. 因为有些应用程序不能为每个这样的延迟写它一个TCP连接的套接字接口,允许应用程序关闭内格尔的算法,通过设置`TCP_NODELAY`选择权. 设置此选项意味着尽快传输数据. 

## 自适应重传

因为TCP保证数据的可靠传输,它将每段如果ACK不在一定的时间内收到. TCP将此超时设置为它期望在连接两端之间的RTT的函数. 不幸的是,由于任何对网络中的主机之间的可能的RTTs的范围,以及相同的两个主机之间随时间RTT的变化,选择合适的超时值是不容易的. 为了解决这个问题,TCP使用了一种自适应的重传机制. 我们现在描述这个机制以及它是如何随着时间的推移而演进的,因为互联网社区使用了TCP获得了更多的经验. 

### 原始算法

我们从一个简单的算法来计算一对主机之间的超时值. 这是算法,最初是在TCP规范描述和说明了它在这些方面也可以通过任何终端到终端的协议. 

其思想是保持RTT的运行平均值,然后计算RTT作为RTT的函数. 具体来说,每次TCP发送数据段时,它记录时间. 当该段的ACK到达时,TCP再次读取时间,然后将这两次之间的差值作为A. `SampleRTT`. 然后TCP计算一个`EstimatedRTT`作为先前估计和新样本之间的加权平均值. 也就是说,

```pseudo
EstimatedRTT = alpha x EstimatedRTT + (1 - alpha) x SampleRTT
```

参数`alpha`选择为*光滑的*这个`EstimatedRTT`. 小的`alpha`跟踪RTT中的变化,但可能受临时波动的影响太大. 另一方面,一个大的`alpha`更稳定,但可能不够快,以适应真正的变化. 原始TCP规范建议设置`alpha`在0.8到0.9之间. 然后使用TCP`EstimatedRTT`以相当保守的方式计算超时: 

```pseudo
TimeOut = 2 x EstimatedRTT
```

### KARN/PARTRAGE算法

在因特网上使用了几年之后,在这个简单的算法中发现了一个相当明显的缺陷. 问题在于,ACK并没有真正确认传输,它实际上确认了数据的接收. 换言之,每当段被重传,然后ACK到达发送方时,为了测量样本RTT,就不可能确定该ACK是否应该与段的第一或第二传输相关联. 有必要知道将它与哪种传输联系起来以便计算准确. `SampleRTT`. 如图所示[图8](#tcp-karn)如果你假设ACK是为原始传输,但它真的是第二个,那么`SampleRTT`太大 (A) ;如果假设ACK是第二次传输,但实际上是第一次,那么`SampleRTT`太小了 (B) . 

<figure class="line">
	<a id="tcp-karn"></a>
	<img src="figures/f05-10-9780123850591.png" width="500px"/>
	<figcaption>Associating the ACK with (a) original transmission
	versus (b) retransmission.</figcaption>
</figure>

1987提出的解决方案出人意料地简单. 每当TCP重传一个段时,它停止取RTT的样本;它只测量`SampleRTT`对于只发送一次的段. 这个解决方案被称为KARN/PARTRIGH算法,在其发明人之后. 他们提出的解决方案还包括TCP超时机制的第二个小改变. 每次TCP重传时,它将下一次超时设置为最后一次超时的两倍,而不是将其基于最后一次超时. `EstimatedRTT`. 也就是说,Karn和Partridge提出TCP使用指数退避,类似于以太网所做的. 使用指数退避的动机很简单: 拥塞是最可能丢失段的原因,这意味着TCP源不应该对超时做出过于积极的反应. 事实上,连接时间越长,源应该变得越谨慎. 我们将在下一章再次看到这一思想,体现在一个更复杂的机制中. 

### 雅各布森/KaRLS算法

当因特网遭受高水平网络拥塞时,引入了KARN/PARTRAGE算法. 他们的方法被设计用于解决导致拥挤的一些原因,但是,尽管它是一种改进,但是拥挤并没有被消除. 第二年 (1988年) ,另外两名研究人员ℴℴ雅各布森和卡莱斯ℴℴ建议对TCP进行更剧烈的改变,以对抗拥塞. 在下一章中描述了大部分建议的变化. 在这里,我们专注于这方面的建议,涉及到决定何时超时和重传一个段. 

另外,应该清楚超时机制如何与拥塞相关ℴℴ如果超时太快,则可能不必要地重新传输一个段,这只会增加网络上的负载. 需要准确超时值的另一个原因是,超时被采取来暗示拥塞,这触发了拥塞控制机制. 最后,请注意,对于TCP特定的雅各布森/KaRLS超时计算没有任何内容. 它可以被任何端到端协议使用. 

原始计算的主要问题是它不考虑样本RTTS的方差. 直观地说,如果样本之间的变异很小,那么`EstimatedRTT`可以更好地信任,并且没有理由将这个估计乘以2来计算超时. 另一方面,样本中的大方差表明超时值不应与`EstimatedRTT`.

在新的方法中,发送者测量一个新的`SampleRTT`像以前一样. 然后将这个新的样本折叠成超时计算如下: 

```pseudo
Difference = SampleRTT - EstimatedRTT
EstimatedRTT = EstimatedRTT + (delta x Difference)
Deviation = Deviation + delta (|Difference| - Deviation)
```

哪里`delta`是0到1之间的分数. 也就是说,我们计算平均RTT和平均值的变化. 

然后TCP计算超时值作为两个函数的函数. `EstimatedRTT`和`Deviation`如下: 

```pseudo
TimeOut = mu x EstimatedRTT + phi x Deviation
```

以经验为基础,`mu`通常设置为1和`phi`设置为4. 因此,当方差小时,`TimeOut`接近`EstimatedRTT`较大的方差导致`Deviation`占主导地位的计算. 

### 实施

关于在TCP中实现超时有两个注意事项. 第一个是,有可能实现计算. `EstimatedRTT`和`Deviation`不使用浮点运算. 取而代之的是,整个计算的规模为2美元$N $ $. `delta`选择为1/2美元$N $ $. 这允许我们进行整数运算,使用移位实现乘法和除法,从而实现更高的性能. 所得计算由下面的代码片段给出,其中n=3 (即,`delta = 1/8`) 注意`EstimatedRTT`和`Deviation`存储在它们的放大表单中,而`SampleRTT`在代码开始时`TimeOut`最后是真实的ㄡ未缩放的值. 如果您发现代码很难理解,那么您可能希望尝试将一些实数插入其中,并验证它给出与上述等式相同的结果. 

```c
{
    SampleRTT -= (EstimatedRTT >> 3);
    EstimatedRTT += SampleRTT;
    if (SampleRTT < 0)
        SampleRTT = -SampleRTT;
    SampleRTT -= (Deviation >> 3);
    Deviation += SampleRTT;
    TimeOut = (EstimatedRTT >> 3) + (Deviation >> 1);
}
```

第二个要点是雅各布森/KaRLS算法只与用于读取当前时间的时钟一样好. 在当时的典型Unix实现中,时钟粒度高达500ms,这明显大于100至200ms之间的某个地方的平均跨国RTT. RY时间这个500毫秒的时钟滴答滴答,只会采取一次往返时间的样本每RTT. 这两个因素的结合可能意味着超时将发生在传输片段后1秒. 再次,TCP的扩展包括使RTT计算更精确的机制. 

我们所讨论的所有重传算法都基于确认超时,这表示一个段可能已经丢失. 但是,请注意,超时不会告诉发送方在丢失的段被成功接收之后发送的任何段. 这是因为TCP确认是累积的;它们仅标识接收到的最后一个段,而没有任何之前的间隙. 由于更快的网络导致更大的窗口,在间隙之后发生的片段的接收更频繁. 如果ACK还告诉发送方已经接收到哪些后续段 (如果有的话) ,那么发送方可以更智能地知道它重传了哪些段,对拥塞状态得出更好的结论,并且做出更好的RTT估计. 支持这一点的TCP扩展在后面的部分中描述. 

## 记录边界

由于TCP是字节流协议,所以发送方写入的字节数不必与接收方读取的字节数相同. 例如,应用程序可以向TCP连接写入8个字节,然后是2个字节,然后是20个字节,而在接收端,应用程序在迭代6次的循环内一次读取5个字节. TCP不会在第八和第九字节之间插入记录边界,也不会在第十和第十一字节之间插入记录边界. 这与面向消息的协议 (如UDP) 形成对比,在该协议中,发送的消息与接收的消息长度完全相同. 

尽管TCP是字节流协议,但它有两个不同的特性,发送者可以使用它来将记录边界插入该字节流,从而通知接收者如何将字节流分解为记录.  (例如,在许多数据库应用程序中,能够标记记录边界是有用的. ) 这两个特性最初都由于完全不同的原因包含在TCP中;它们只是随着时间的推移才被用于此目的. 

第一个机制是紧急数据特性,由`URG`旗与`UrgPtr`TCP报头中的字段. 最初,紧急数据机制被设计为允许发送应用程序发送. *带外*数据到它的对等点. 所谓"带外"是指独立于正常数据流的数据 (例如,中断已经在进行中的操作的命令) . 这种带外数据在段中使用`UrgPtr`字段并在到达时立即传递给接收进程,即使这意味着在序列号较早的数据之前传递它. 然而,随着时间的推移,这个特性还没有被使用,因此它已经不再表示"紧急"数据,而是用来表示"特殊"数据,例如记录标记. 之所以有这种用法,是因为与推送操作一样,接收端的TCP必须通知应用程序紧急数据已经到达. 也就是说,紧急数据本身并不重要. 事实上,发送过程可以有效地向接收机发送一个重要的信号. 

将记录结束标记插入字节的第二种机制是*推*操作. 最初,这种机制被设计成允许发送进程告诉TCP,它应该发送 (刷新) 它收集到的任何字节到它的对等端. 这个*推*操作可用于实现记录边界,因为规范规定,当应用程序说push时,TCP必须发送它在源处缓冲的任何数据,并且可选地,当传入的段设置PUSH标志时,目的地的TCP通知应用程序. 如果接收端支持这个选项 (套接字接口不支持) ,那么可以使用推送操作将TCP流分解为记录. 

当然,应用程序总是可以自由地插入记录边界而不需要任何来自TCP的帮助. 例如,它可以发送一个指示要跟随的记录长度的字段,或者它可以将自己的记录边界标记插入数据流中. 

## TCP扩展

在本节中,我们已经在四个不同的地方提到,现在存在TCP的扩展,这有助于减轻TCP在基础网络变得更快时所面临的一些问题. 这些扩展被设计成对TCP有尽可能小的影响. 特别是,它们被实现为可以添加到TCP报头的选项.  (我们更早地讨论了这一点,但是TCP报头有一个原因`HdrLen`字段表示报头可以是可变长度的;TCP报头的可变部分包含已经添加的选项. ) 添加这些扩展作为选项而不是更改TCP报头的核心的重要意义在于,即使主机没有使用TCP进行通信,它们仍然可以使用TCP进行通信不执行选项. 然而,实现可选扩展的主机可以利用它们. 双方同意在TCP连接建立阶段使用这些选项. 

第一个扩展有助于改进TCP的超时机制. TCP不需要使用粗粒度事件来测量RTT,而是可以在将要发送段时读取实际的系统时钟,并将这个时间段设为32位*时间戳*-在段的标题中. 然后,接收方将此时间戳回送给发送方进行确认,发送方从当前时间中减去此时间戳以测量RTT. 本质上,时间戳选项为TCP提供了一个方便的地方来存储传输段时的记录;它把时间存储在段本身中. 注意,连接中的端点不需要同步时钟,因为时间戳是在连接的同一端写入和读取的. 

第二个扩展解决了TCP 32位的问题. `SequenceNum`在高速网络上过早地环绕现场. TCP没有定义新的64位序列号字段,而是使用刚刚描述的32位时间戳来有效地扩展序列号空间. 换言之,TCP基于是否具有一个64位标识符来决定是否接受或拒绝一个段. `SequenceNum`低阶32位中的字段和高阶32位中的时间戳. 由于时间戳总是在增加,所以它用于区分相同序列号的两个不同体现. 请注意,在此设置中使用时间戳只是为了防止卷绕;它不是为了排序或确认数据而作为序列号的一部分. 

第三个扩展允许TCP通告一个更大的窗口,从而允许它填充高速网络所允许的更大的延迟$乘以$带宽管道. 此扩展涉及定义一个选项的选项. *比例因子*广告窗口. 也就是说,而不是解释出现在`AdvertisedWindow`字段表示允许发送方拥有未确认的字节数,此选项允许TCP双方同意`AdvertisedWindow`字段计数较大的块 (例如,发送者可以有多少个16字节的数据单元未被确认) . 换句话说,窗口缩放选项指定每个边应该留下多少位移位. `AdvertisedWindow`在使用其内容来计算有效窗口之前的字段. 

第四个扩展允许TCP通过选择性地确认已接收但不与先前接收的所有段相邻的任何附加段来增强其累积确认. 这就是*选择性确认*或*麻袋*,选项. 当使用SACK选项时,接收方继续确认段的正常含义. `Acknowledge`字段不改变,但它还使用报头中的可选字段来确认接收数据的任何其他块. 这允许发送者只根据选择性确认重新发送缺失的片段. 

没有解雇,只有两个合理的策略为发送者. 悲观策略通过重传超时的段以及随后传输的任何段来响应超时. 实际上,悲观策略的假设是最坏的: 所有这些环节都丢失了. 悲观策略的缺点是,它可以不必要地重新传输首次成功接收的段. 另一种策略是乐观策略,它通过只重发超时的段来响应超时. 实际上,乐观的方法假定最乐观的情况: 只有一个部分已经丢失. 乐观策略的缺点是,当一系列连续的段丢失时,它非常慢,不必要,就像在拥塞时可能发生的那样. 这是缓慢的,因为直到发送方接收到用于重传前一段的ACK,才发现每个段的丢失. 因此,它消耗一个RTT每段,直到它已经重发的所有部分在丢失系列. 使用SACK选项,发送者可以使用更好的策略: 只重传那些填补了已选择性确认的段之间的空白的段. 

顺便说一下,这些扩展并不是完整的故事. 当我们研究TCP如何处理拥塞时,我们将在下一章中看到更多的扩展. Internet分配号码管理局 (IANA) 跟踪为TCP (以及许多其他Internet协议) 定义的所有选项. 在编写时,大约有30个TCP选项被定义 (很多是实验性的或过时的) . 请参阅本章末尾的参考资料,链接到IANA的协议号注册表. 

## 性能

回想第1章介绍了评估网络性能的两个定量指标: 延迟和吞吐量. 如该讨论中所提到的,这些度量不仅受到底层硬件 (例如,传播延迟和链路带宽) 的影响,而且还受到软件开销的影响. 现在,我们已经有了完整的基于软件的协议图,其中包括替代传输协议,我们可以讨论如何有意义地度量它的性能. 这些测量的重要性在于它们代表应用程序所看到的性能. 

<figure class="line">
	<a id="experiment"></a>
	<img src="figures/f05-11-9780123850591.png" width="500px"/>
	<figcaption>Measured system: Two Linux workstations and a pair of
	Gbps Ethernet links.</figcaption>
</figure>

我们开始,任何报告的实验结果应该通过描述我们的实验方法. 这包括实验中使用的设备;在这种情况下,每个工作站都有一对运行Linux的双CPU 2.4-GHz Xeon处理器. 为了实现超过1Gbps的速度,在每台机器上使用一对以太网适配器 (标记为.,用于网络接口卡) . 以太网跨越单个机房,所以传播不是问题,这是衡量处理器/软件开销的尺度. 运行在套接字接口之上的测试程序只是试图尽可能快地将数据从一台机器传输到另一台机器. [图9](#experiment)说明了设置. 

您可能注意到,这个实验装置在硬件或链路速度方面并不是特别流血的边缘. 本节的重点不是说明特定协议可以运行多快,而是说明测量和报告协议性能的一般方法. 

使用标准的标称工具TTCP对各种消息大小执行吞吐量测试. 文中给出了吞吐量测试的结果. [图10](#xput). 在这个图中要注意的关键是吞吐量随着消息的变大而提高. 这很有道理ℴℴ每个消息都包含一定量的开销,所以较大的消息意味着这个开销被摊销到更多的字节上. 吞吐量曲线在1KB以上变平,此时与协议栈必须处理的大量字节相比,每条消息的开销变得微不足道. 

<figure class="line">
	<a id="xput"></a>
	<img src="figures/f05-12-9780123850591.png" width="400px"/>
	<figcaption>Measured throughput using TCP, for various message
	sizes.</figcaption>
</figure>

值得注意的是,在这个设置中,最大吞吐量小于2 Gbps,可用链路速度. 进一步的测试和分析结果将需要找出瓶颈在哪里 (或者如果有不止一个) . 例如,查看CPU负载可以指示CPU是否是瓶颈,或者内存带宽ㄡ适配器性能或其他问题是否应该受到指责. 

我们还注意到,这个测试中的网络基本上是"完美的". 它几乎没有延迟或丢失,所以影响性能的唯一因素是TCP实现和工作站的硬件和软件. 相比之下,大多数时候我们处理的网络远非完美,尤其是带宽受限的ㄡ最后一英里链路和容易丢失的无线链路. 在我们完全了解这些链接如何影响TCP性能之前,我们需要了解TCP是如何处理的. *拥塞*这是下一章的主题. 

在网络化历史的各个时期,网络链接的稳步增长速度已经威胁到要比能够传递给应用程序的东西更快地运行. 例如,美国在1989年开始进行大规模研究,以建立"千兆位网络",其目标不仅是建立可以运行在1Gbps或更高的链路和交换机,而且还要将吞吐量一直传递到单个应用程序进程. 存在一些实际问题 (例如,网络适配器ㄡ工作站架构和操作系统都必须考虑网络到应用程序的吞吐量来设计) ,还有一些感知到的问题,结果并不那么严重. 这类问题的首要问题是,现有的传输协议,特别是TCP,可能无法应对千兆位操作的挑战. 

事实证明,TCP已经很好地适应了高速网络和应用的日益增长的需求. 最重要的因素之一是引入窗口缩放来处理更大的带宽延迟产品. 然而,TCP的理论性能与实践中所取得的结果往往存在很大差异. 当数据从网络适配器传递到应用程序时,复制次数多于必要次数等相对简单的问题会降低性能,当带宽延迟乘积较大时,缓冲存储器不足也会降低性能. TCP的动态特性足够复杂 (在下一章中将变得更加明显) ,网络行为ㄡ应用程序行为和TCP协议本身之间的微妙交互可以显著地改变性能. 

出于我们的目的,值得注意的是,TCP继续很好地执行以及网络速度的提高,并且当它遇到一些限制 (通常与拥塞ㄡ增加带宽延迟产品或两者有关) 时,研究人员会蜂拥而至寻找解决方案. 我们已经看到了本章中的一些内容,我们将在下一节中看到更多. 

## 替代设计选择

尽管TCP已经被证明是满足广泛应用需求的健壮协议,但是传输协议的设计空间相当大. TCP决不是设计空间中唯一有效的点. 我们总结TCP的考虑通过考虑替代设计选择. 虽然我们为TCP的设计者做出选择提供了解释,但我们观察到存在做出其他选择的其他协议,并且将来可能出现更多这样的协议. 

首先,我们已经从本书的第一章中建议至少有两类有趣的传输协议: 面向流的协议 (如TCP) 和请求/应答协议 (如RPC) . 换句话说,我们隐式地将设计空间一分为二,并将TCP正好放置在面向流的世界一半. 我们可以进一步将面向流的协议分成两组ℴℴ可靠和不可靠ℴℴ前者包含TCP,后者更适合于交互式视频应用,后者宁愿丢弃帧也不愿引起与重传相关的延迟. 

构建传输协议分类法的这个练习很有趣,并且可以越来越详细地继续下去,但是世界并不像我们想象的那样黑白分明. 例如,考虑TCP作为请求/应答应用程序的传输协议的适用性. TCP是全双工协议,因此很容易在客户端和服务器之间打开TCP连接,在一个方向上发送请求消息,而在另一个方向上发送应答消息. 然而,有两个并发症. 第一个是TCP是一个*字节*面向协议,而不是*消息*面向协议和请求/应答应用程序总是处理消息.  (我们稍后将更详细地讨论字节对消息的问题. ) 第二个复杂性在于,在请求消息和应答消息都适合于单个网络分组的情况下,设计良好的请求/应答协议只需要两个分组即可实现exch. ange,而TCP至少需要9: 3来建立连接,两个用于消息交换,四个用于断开连接. 当然,如果请求或应答消息足够大,需要多个网络分组 (例如,发送100000字节应答消息可能需要100个分组) ,则建立和断开连接的开销是不重要的. 换言之,特定协议不能支持特定功能的情况并不总是这样;在某些情况下,有时一种设计比另一种设计更有效. 

其次,正如刚才所建议的,您可能会质疑为什么TCP选择提供可靠的信息. *字节*流服务而不是可靠服务*消息*流服务;对于要交换记录的数据库应用程序来说,消息是自然的选择. 这个问题有两个答案. 首先,按照消息定义的协议,必须定义消息大小的上限. 毕竟,无限长的消息是字节流. 对于协议选择的任何消息大小,都会有应用程序希望发送更大的消息,使传输协议变得无用,并迫使应用程序实现自己的传输类服务. 第二个原因是,虽然面向消息的协议绝对更适合于希望彼此发送记录的应用程序,但是您可以轻松地将记录边界插入字节流以实现此功能. 

在TCP的设计中做出的第三个决定是它提供字节. *整齐*应用程序. 这意味着它可以保留从网络无序接收的字节,等待一些丢失的字节来填充一个漏洞. 这对于许多应用程序非常有用,但如果应用程序能够无序地处理数据,则结果会非常有用. 作为一个简单的示例,包含多个嵌入图像的网页在开始显示页面之前不需要按顺序传递所有图像. 事实上,有一类应用程序更喜欢在应用程序层处理无序数据,以换取在网络内丢弃或无序分组时更快地获得数据. 支持这样的应用程序的愿望导致创建另一个IETF标准传输协议,称为*流控制传输协议* (SCTP) . SCTP提供了部分有序的传递服务,而不是TCP的严格有序服务.  (SCTP还做出一些与TCP不同的其他设计决策,包括消息定向和对单个会话的多个IP地址的支持) . 详情请参阅进一步阅读部分. 

第四,TCP选择实现显式设置/拆卸阶段,但这不是必需的. 在连接建立的情况下,当然可以连同第一数据消息一起发送所有必要的连接参数. TCP选择采取更保守的方法,使接收器有机会在任何数据到达之前拒绝连接. 在拆卸的情况下,我们可以悄悄地关闭一个已经长时间不活动的连接,但是这会使像Telnet这样的应用程序变得复杂,这些应用程序希望一次保持连接存活数周;这些应用程序将被迫向以下发送带外".."消息保持连接状态在另一端消失. 

最后,TCP是基于窗口的协议,但这不是唯一的可能性. 另一种选择是*基于速率*设计,其中接收方告诉发送方愿意接受传入数据的速率-以字节或每秒分组表示. 例如,接收器可以通知发送者,它可以容纳100个包一秒钟. 窗口和速率之间有一个有趣的二元性,因为窗口中的数据包 (字节) 的数量除以RTT,就是速率. 例如,10包的窗口大小和100ms的RTT意味着允许发送方以每秒100包的速率发送. 正是通过增加或减小所广告的窗口大小,接收机才能有效地提高或降低发送方能够发送的速率. 在TCP,这个信息被反馈给发送者. `AdvertisedWindow`每个段的ACK字段. 在基于速率的协议中,关键问题之一是期望速率 (可能随时间而变化) 多长时间被中继回源: 它是针对每个分组ㄡ每个RTT一次,还是仅当速率改变时?虽然我们刚刚在流量控制的上下文中考虑了窗口与速率的关系,但是在拥塞控制的上下文中,这是一个更具争议性的问题,我们将在下一章中讨论. 
